plot(x.test,y.test)
plot(x.test,y.pred)
points(x.test,y.pred)
points(x.test,y.pred)
points(x.test,y.pred)
plot(x.train,y.train)
points(x.test,y.pred)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "blue")
points(x.train,y.pred, col = "yellow")
points(x.test,y.pred, col = "yellow")
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "blue")
points(x.test,y.pred, col = "yellow")
points(x.test,y.pred,pch = 15, col = "yellow")
points(x.test,y.pred,pch = 15, col = "yellow", cex = 0.6)
View(AutoTrain)
View(AutoTest)
AutoTrain=read.csv("AutoTrain.csv",header=T,na.strings="?")
# Get variables of interest
x.train = AutoTrain$horsepower
y.pred = kNN(2,x.train,y.train,x.pred)
y.pred = kNN(2,x.train,y.train,x.test)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.pred,pch = 15, col = "yellow", cex = 0.6)
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
points(x.test,y.test,col = "green")
y.pred = kNN(5,x.train,y.train,x.test)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
y.pred = kNN(10,x.train,y.train,x.test)
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
points(x.test,y.test,col = "dark red")
AutoTrain = AutoTest[order(AutoTrain$horsepower)]
AutoTrain = AutoTrain[order(AutoTrain$horsepower)]
df <-AutoTrain[order(AutoTrain$horsepower),]
View(df)
AutoTrain = AutoTrain[order(AutoTrain$horsepower),]
View(df)
View(AutoTrain)
AutoTest = AutoTest[order(AutoTest$horsepower),]
x.train = AutoTrain$horsepower
y.train = AutoTrain$mpg
x.test = AutoTest$horsepower
y.test = AutoTest$mpg
rm(list = ls())
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
dstar = d[order(d)[k]]
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
# Load in the data
AutoTrain=read.csv("AutoTrain.csv",header=T,na.strings="?")
AutoTrain = AutoTrain[order(AutoTrain$horsepower),]
AutoTest=read.csv("AutoTest.csv",header=T,na.strings="?")
AutoTest = AutoTest[order(AutoTest$horsepower),]
# Get variables of interest
x.train = AutoTrain$horsepower
x.test = AutoTest$horsepower
y.train = AutoTrain$mpg
y.test = AutoTest$mpg
# Setup the loop variables
k = c(2,5,10,20,30,50,100)
MSE.Train = numeric(length(k))
MSE.Test = numeric(length(k))
#Loop over every value of k, train the data and compute the MSE
for (i in 1:length(k)){
y.pred = kNN(k[i],x.train,y.train,x.test)
MSE.Train[i] = mean((y.train - y.pred)^2)
MSE.Test[i] = mean((y.test - y.pred)^2)
}
MSE.Test
MSE.Train
#Loop over every value of k, train the data and compute the MSE
for (i in 1:length(k)){
y.pred = kNN(k[i],x.train,y.train,x.train)
MSE.Train[i] = mean((y.train - y.pred)^2)
MSE.Test[i] = mean((y.test - y.pred)^2)
}
y.pred = kNN(k[i],x.train,y.train,x.test)
#Loop over every value of k, train the data and compute the MSE
for (i in 1:length(k)){
y.pred = kNN(k[i],x.train,y.train,x.test)
MSE.Train[i] = mean((y.train - y.pred)^2)
MSE.Test[i] = mean((y.test - y.pred)^2)
}
MSE.Test
MSE.Train
#Loop over every value of k, train the data and compute the MSE
for (i in 1:length(k)){
y.pred_train = kNN(k[i],x.train,y.train,x.train)
y.pred_test = kNN(k[i],x.train,y.train,x.test)
MSE.Train[i] = mean((y.train - y.pred_train)^2)
MSE.Test[i] = mean((y.test - y.pred_test)^2)
}
MSE.Test
warnings()
MSE.Train
y.pred_train = kNN(k[i],x.train,y.train,x.train)
d
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
print(d)
dstar = d[order(d)[k]]
print(dstar)
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
y.pred_train = kNN(k[i],x.train,y.train,x.train)
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
dstar = d[order(d)[k]]
print(dstar)
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
y.pred_train = kNN(k[i],x.train,y.train,x.train)
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
print(d)
dstar = d[order(d)[k]]
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
y.pred_train = kNN(k[1],x.train,y.train,x.train)
y.pred_train = kNN(2,x.train,y.train,x.train)
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
print(d)
dstar = d[order(d)[k]]
print(dstar)
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
y.pred_train = kNN(2,x.train,y.train,x.train)
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
dstar = d[order(d)[k]]
print(d <= dstar)
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
y.pred_train = kNN(2,x.train,y.train,x.train)
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
dstar = d[order(d)[k]]
print(order(d)[k])
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
y.pred_train = kNN(2,x.train,y.train,x.train)
print(d)
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
dstar = d[order(d)[k]]
print(order(d)[k])
print(d)
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
y.pred_train = kNN(2,x.train,y.train,x.train)
kNN <- function(k,x.train,y.train,x.pred) {
#
## This is kNN regression function for problems with
## 1 predictor
#
## INPUTS
#
# k       = number of observations in nieghbourhood
# x.train = vector of training predictor values
# y.train = vector of training response values
# x.pred  = vector of predictor inputs with unknown
#           response values
#
## OUTPUT
#
# y.pred  = predicted response values for x.pred
## Initialize:
n.pred <- length(x.pred);		y.pred <- numeric(n.pred)
## Main Loop
for (i in 1:n.pred){
d <- abs(x.train - x.pred[i])
dstar = d[order(d)[k]]
y.pred[i] <- mean(y.train[d <= dstar])
}
## Return the vector of predictions
invisible(y.pred)
}
#Loop over every value of k, train the data and compute the MSE
# This is run twice to ensure the data has the proper X positions.
for (i in 1:length(k)){
y.pred_train = kNN(k[i],x.train,y.train,x.train)
y.pred_test = kNN(k[i],x.train,y.train,x.test)
MSE.Train[i] = mean((y.train - y.pred_train)^2)
MSE.Test[i] = mean((y.test - y.pred_test)^2)
}
MSE.Train
MSE.Test
plot(1/k,MSE.Train,col = 'red', lwd = 4, type = 'l', main = 'Testing and Training Error vs. 1/k', xlab = '1/k', ylab = 'MSE')
plot(1/k,MSE.Train,col = 'red', lwd = 4, type = 'l', main = 'Testing and Training Error vs. 1/k', xlab = '1/k', ylab = 'MSE')
points(1/k,MSE.Test,col = 'blue', lwd = 4, type = 'l')
legend("topright",legend = c("MSE_Te", "MSE_Tr"),
col = c("red","blue"),lwd = 4,
text.col = "black",
horiz = FALSE)
plot(1/k,MSE.Train,col = 'red', lwd = 4, type = 'l', main = 'Testing and Training Error vs. 1/k', xlab = '1/k', ylab = 'MSE')
points(1/k,MSE.Test,col = 'blue', lwd = 4, type = 'l')
legend("topright",legend = c("MSE_Te", "MSE_Tr"),
col = c("red","blue"),lwd = 4,
text.col = "black",
horiz = FALSE)
plot(1/k,MSE.Train,col = 'red', lwd = 4, type = 'l', main = 'Testing and Training Error vs. 1/k', xlab = '1/k', ylab = 'MSE')
points(1/k,MSE.Test,col = 'blue', lwd = 4, type = 'l')
legend("topright",legend = c("MSE_Te", "MSE_Tr"),
col = c("red","blue"),lwd = 4,
text.col = "black",
horiz = FALSE)
plot(1/k,MSE.Train,col = 'red', lwd = 4, type = 'l', main = 'Testing and Training Error vs. 1/k', xlab = '1/k', ylab = 'MSE')
points(1/k,MSE.Test,col = 'blue', lwd = 4, type = 'l')
legend("topright",legend = c("MSE_Tr", "MSE_Te"),
col = c("red","blue"),lwd = 4,
text.col = "black",
horiz = FALSE)
plot(1/k,MSE.Train,col = 'red', lwd = 4, type = 'l', main = 'Testing and Training Error vs. 1/k', xlab = '1/k', ylab = 'MSE')
points(1/k,MSE.Test,col = 'blue', lwd = 4, type = 'l')
legend("topright",legend = c("MSE_Tr", "MSE_Te"),
col = c("red","blue"),lwd = 4,
text.col = "black",
horiz = FALSE)
plot(k,MSE.Train,col = 'red', lwd = 4, type = 'l', main = 'Testing and Training Error vs. 1/k', xlab = '1/k', ylab = 'MSE')
points(k,MSE.Test,col = 'blue', lwd = 4, type = 'l')
legend("topright",legend = c("MSE_Tr", "MSE_Te"),
col = c("red","blue"),lwd = 4,
text.col = "black",
horiz = FALSE)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
# Code to test out plotting
y.pred_test = kNN(20,x.train,y.train,x.test)
y.pred_test = kNN(20,x.train,y.train,x.test)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
# Code to test out plotting
y.pred_test = kNN(20,x.train,y.train,x.test)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
# Code to test out plotting
y.pred_test = kNN(20,x.train,y.train,x.train)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
y.pred_test = kNN(10,x.train,y.train,x.train)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
y.pred = kNN(20,x.train,y.train,x.train)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),
text.col = "black",
horiz = FALSE)
y.pred = kNN(20,x.train,y.train,x.train)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),
text.col = "black",
horiz = FALSE)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),
text.col = "black",type = 'o',
horiz = FALSE)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'), type = 'o',
text.col = "black",
horiz = FALSE)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'), type = 'l',
text.col = "black",
horiz = FALSE)
y.pred = kNN(20,x.train,y.train,x.train)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
y.pred = kNN(20,x.train,y.train,x.test)
plot(x.train,y.train,col = "red" , main = "Training, Testing and Prediction of MPG vs. Horsepower",
xlab = "Horsepower", ylab = "MPG")
points(x.test,y.test,col = "dark red")
points(x.test,y.pred,pch = 15, col = "blue", cex = 0.6)
legend("topright",legend = c("Training Data", "Testing Data", "Prediction" ),
col = c("red","dark red",'blue'),lwd = 4,
text.col = "black",
horiz = FALSE)
